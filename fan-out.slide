Lightning Fast Events
Emitting in a concurrent world

Jamie Cuthill
6 May 2020
jc@flyt.io

* Background

The [[https://github.com/flypay/flyt-monolith-bridge-plu-mapper][PLU bridge]] receives a `menu_changed` webhook and is responsible for raising PLU discovered events for that new menu. 

We receive a huge payload with thousands of mappings.

	{
		"reference": "ML:AU:11003791",
		"mappings": [
			{
				"plus": ["2884.2:2883"],
				"uuid": "996c72ec-9d52-5449-85d4-a50ea513f9a7"
			},
			{
				"plus": ["2884.2:2883"],
				"portionID": "996c72ec-9d52-5449-85d4-a50ea513f9a7",
				"uuid": "52183600-c7ed-5232-afcc-f79d84fc3913"
			},
			...
	}

* Implementation

- Iterate through the mappings array
- Emit each PLU discovered events
- Profit.

	for _, item := range Mappings {
		for _, plu := range item.Plus {
			Emit(ctx, &flyt.PluDiscovered{
				Plu:          plu,
				ItemId:       item.UUID,
				RestaurantId: restID,
				ParentId:     item.ParentID,
				PortionId:    item.PortionID,
			})
		}
	}

* In Practice

The `Emit()` call can take anywhere from 50ms up to 6s and is called in sequence.

The result was very slow and consumed a lot of memory.

.image fan-out/images/elapsedtime.png
.caption Yes that is in minutes (per location)

* Optimising

* Concurrency

We can leverage Go's fantastic concurrency primitives to optimise things 
that are slow that can also be parallelised.

- channels
- goroutines

.image fan-out/images/concurrent-flow.png

* Re-implementing

The technique here is similar to [[https://blog.golang.org/pipelines][fan-out]] or [[https://gobyexample.com/worker-pools][worker pooling]].

We create a channel and start `n` workers (tune `n` as you see fit).

	queue := make(chan flyt.PluDiscovered)

	for i := n; i > 0; i-- {
		go worker(queue)
	}

	func worker(in chan flyt.PluDiscovered) {
		for event := range in {
			Emit(ctx, &ev)
		}
	}

* Re-implementing

Now we just need to alter our original for loop to push the event into the queue.

	for _, item := range Mappings {
		for _, plu := range item.Plus {
			queue <- flyt.PluDiscovered{
				Plu:          plu,
				ItemId:       item.UUID,
				RestaurantId: restID,
				ParentId:     item.ParentID,
				PortionId:    item.PortionID,
			}
		}
	}

* Without Synchronisation

.play fan-out/samples/concurrent-nosync.go /START OMIT/,/END OMIT/

* What would this output?

* 

The output of the previous sample is indeterminate and incomplete

	start
	emit 5
	emit 3
	emit 4
	emit 1
	emit 2
	done
	emit 7
	emit 10

Complete ❌ 

What happened to 6, 8 and 9?

* ⏳ Waiting

.play fan-out/samples/concurrent-sync.go /START OMIT/,/END OMIT/

.code fan-out/samples/concurrent-sync.go /STARTW OMIT/,/ENDW OMIT/

* 

Now our output looks more like you would expect

	start
	emit 5
	emit 2
	emit 3
	emit 4
	emit 1
	emit 6
	emit 8
	emit 7
	emit 9
	emit 10
	done

Complete ✅ 

* Analysis

How does this new code perform? 

.image fan-out/images/elapsedtime-after.png

.caption With 100 workers, even the largest menus are now under 1m

* When can I apply this?

- Work where the order does not matter.
- Slow processes that can run in parallel.

*Examples*

- Fetching many records from a data store.
- Making independent HTTP requests.
